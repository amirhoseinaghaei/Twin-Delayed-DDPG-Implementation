{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Y2nGdtlKVydr",
        "Jb7TTaHxWbQD",
        "HRDDce8FXef7",
        "NzIDuONodenW",
        "ka-ZRtQvjBex",
        "gGuKmH_ijf7U",
        "Hjwf2HCol3XP",
        "kop-C96Aml8O",
        "qEAzOd47mv1Z",
        "5YdPG4HXnNsh",
        "HWEgDAQxnbem",
        "ZI60VN2Unklh",
        "QYOpCyiDnw7s",
        "xm-4b3p6rglE",
        "31n5eb03p-Fm",
        "q9gsjvtPqLgT",
        "wi6e2-_pu05e"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amirhoseinaghaei/Twin-Delayed-DDPG-Implementation/blob/main/TD3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXu1r8qvSzWf"
      },
      "source": [
        "# Twin-Delayed DDPG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRzQUhuUTc0J"
      },
      "source": [
        "## Installing the packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAHMB0Ze8fU0"
      },
      "source": [
        "!pip install pybullet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xjm2onHdT-Av"
      },
      "source": [
        "## Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ikr2p0Js8iB4"
      },
      "source": [
        "import os\n",
        "import time\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "# import pybullet_envs\n",
        "import gym\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from gym import wrappers\n",
        "from torch.autograd import Variable\n",
        "from collections import deque"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1 which is implementing ReplayBuffer"
      ],
      "metadata": {
        "id": "C70obyzEvamP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ReplayBuffer(object):\n",
        "  def __init__(self, max_size = 1e6):\n",
        "    self.storage = []\n",
        "    self.max_size = max_size\n",
        "    self.ptr = 0\n",
        "  def add(self, transition):\n",
        "    if len(self.storage) == self.max_size:\n",
        "        self.storage[int(self.ptr)] = transition\n",
        "        self.ptr = (self.ptr + 1)% self.max_size\n",
        "    else:\n",
        "        self.storage.append(transition)\n",
        "\n",
        "  def sample(self, batch_size):\n",
        "      ind = np.random.randint(0, len(self.storage), size = batch_size)\n",
        "      batch_states, batch_next_states, batch_actions, batch_rewards, batch_dones = [], [], [], [], []\n",
        "      for i in ind:\n",
        "        state, next_state, action, reward, done = self.storage[i]\n",
        "        batch_states.append(np.array(state, copy = False))\n",
        "        batch_next_states.append(np.array(next_state, copy = False))\n",
        "        batch_actions.append(np.array(action, copy = False))\n",
        "        batch_rewards.append(np.array(reward, copy = False))\n",
        "        batch_dones.append(np.array(done, copy = False))\n",
        "      return np.array(batch_states), np.array(batch_next_states), np.array(batch_actions), np.array(batch_rewards).reshape(-1,1), np.array(batch_dones).reshape(-1,1)\n"
      ],
      "metadata": {
        "id": "BiT5FpCsEiJ_"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2 which is defining the Actor neural network"
      ],
      "metadata": {
        "id": "maJ5dbMQvjFX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Actor(nn.Module):\n",
        "  def __init__(self, state_dim, action_dim, max_action):\n",
        "      super(Actor, self).__init__()\n",
        "      self.layer1 = nn.Linear(state_dim, 400)\n",
        "      self.layer2 = nn.linear(400,300)\n",
        "      self.layer3 = nn.Linear(300, action_dim)\n",
        "      self.max_action = max_action\n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.layer1(x))\n",
        "    x = F.relu(self.layer2(x))\n",
        "    x = self.max_action * nn.Tanh(self.layer3(x))\n",
        "    return x "
      ],
      "metadata": {
        "id": "rN3ZHZbQvrW-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3 which is defining the Critic neural network"
      ],
      "metadata": {
        "id": "SviauDv50LTR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Critic(nn.Module):\n",
        "  def __init__(self, state_dim , action_dim):\n",
        "      super(Critic, self).__init__()\n",
        "      # Defining the first Critic neural network\n",
        "      self.layer1 = nn.Linear(state_dim + action_dim, 400)\n",
        "      self.layer2 = nn.linear(400,300)\n",
        "      self.layer3 = nn.Linear(300, 1)\n",
        "      # Defining the second Critic neural network\n",
        "      self.layer4 = nn.Linear(state_dim + action_dim, 400)\n",
        "      self.layer5 = nn.linear(400,300)\n",
        "      self.layer6 = nn.Linear(300, 1)\n",
        "  def forward(self, x, u):\n",
        "    xu = torch.cat([x,u],1)\n",
        "    # Forward propagation on the first Critic neural network\n",
        "    x1 = F.relu(self.layer1(xu))\n",
        "    x1 = F.relu(self.layer2(x1))\n",
        "    x1 = self.layer3(x1)\n",
        "    # Forward propagation on the second Critic neural network\n",
        "    x2 = F.relu(self.layer4(xu))\n",
        "    x2 = F.relu(self.layer5(x2))\n",
        "    x2 = self.layer6(x2)\n",
        "    return x1, x2 \n",
        "  def Q1(self, x, u):\n",
        "    xu = torch.cat([x,u],1)\n",
        "    x1 = F.relu(self.layer1(xu))\n",
        "    x1 = F.relu(self.layer2(x1))\n",
        "    x1 = self.layer3(x1)\n",
        "    return x1"
      ],
      "metadata": {
        "id": "xPWCn6Qu0QjB"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4  which is creating the TD3 class"
      ],
      "metadata": {
        "id": "5zRxQyB5200a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Selecting the device (CPU or GPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Building the whole training process into a class\n",
        "\n",
        "class TD3(object):\n",
        "  def __init__(self, state_dim, action_dim, max_action):\n",
        "    self.actor = Actor(state_dim, action_dim, max_action)\n",
        "    self.actor_target = Actor(state_dim, action_dim, max_action)\n",
        "    self.actor_target.load_state_dict(self.actor.state_dict())\n",
        "    self.actor_optimizer = torch.optim.Adam(self.actor.parameters)\n",
        "    self.critic = Critic(state_dim, action_dim)\n",
        "    self.critic_target = Critic(state_dim, action_dim)\n",
        "    self.critic_target.load_state_dict(self.critic.state_dict())\n",
        "    self.critic_optimizer = torch.optim.Adam(self.critic.parameters())\n",
        "    self.max_action = max_action\n",
        "  def select_action(self, state):\n",
        "    state = torch.Tensor(state.reshape(1,-1))\n",
        "    return self.actor(state).cpu().data.numpy().flatten()   \n",
        "  def train(self, replay_buffer, iterations, batch_size =100, discount = 0.99, tau = 0.005, policy_noise = 0.2, noise_clip = 0.5, policy_freq = 2):\n",
        "    for i in range(iterations):\n",
        "      \n"
      ],
      "metadata": {
        "id": "Ud1WPfjP25Oh"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BFMt3mKX4YFx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}